# Example 3
# estimate the function for different quantile levels
data(mcycle, package = "MASS")
attach(mcycle)
plot(times, accel, xlab = "milliseconds", ylab = "acceleration")
taus <- c(0.1, 0.25, 0.5, 0.75, 0.9)
for(i in 1:length(taus)) {
fit <- llqr(times, accel, tau = taus[i])$ll_est
lines(times, fit, lty = i)
}
legend(45, -50, c("tau=0.1","tau=0.25","tau=0.5","tau=0.75", "tau=0.9"),
lty=1:length(taus))
# Example 4
# demonstrate a situation where the dimension of the predictor is large and
# the local linear fitting meets the 'curse of dimensionality' problem
set.seed(1234)
n <- 100
p <- 10
x <- matrix(rnorm(n * p), n, p)
error <- rnorm(n)
y <- 3 * x[, 1] + x[, 2] + error
tau <- 0.5
# use the following instead of llqr(x, y, tau = tau)
fit.alt <- llqr(x, y, tau = tau, h=1)
fit.alt
# Example 1
# estimate the function at a specific quantile level for simulated data
set.seed(1234)
n <- 100
x <- rnorm(n)
error <- rnorm(n)
y <- (x + 1)^3 + 0.1 * (x - 2)^3 + error
tau <- 0.5
plot(x, y, main = tau)
points(x, llqr(x, y, tau = tau)$ll_est, col = 'red', pch = 16)
# Example 2
# estimate the function at a point x0
set.seed(1234)
n <- 100
x <- rnorm(n)
error <- rnorm(n)
y <- (x + 1)^3 + 0.1 * (x - 2)^3 + error
tau <- 0.5
x0 <- 1
llqr(x, y, tau = tau, x0 = x0)
# Example 3
# estimate the function for different quantile levels
data(mcycle, package = "MASS")
attach(mcycle)
plot(times, accel, xlab = "milliseconds", ylab = "acceleration")
taus <- c(0.1, 0.25, 0.5, 0.75, 0.9)
for(i in 1:length(taus)) {
fit <- llqr(times, accel, tau = taus[i])$ll_est
lines(times, fit, lty = i)
}
legend(45, -50, c("tau=0.1","tau=0.25","tau=0.5","tau=0.75", "tau=0.9"),
lty=1:length(taus))
# Example 4
# demonstrate a situation where the dimension of the predictor is large and
# the local linear fitting meets the 'curse of dimensionality' problem
set.seed(1234)
n <- 100
p <- 10
x <- matrix(rnorm(n * p), n, p)
error <- rnorm(n)
y <- 3 * x[, 1] + x[, 2] + error
tau <- 0.5
# use the following instead of llqr(x, y, tau = tau)
fit.alt <- llqr(x, y, tau = tau, h=1)
fit.alt
# estimate the directions of a single-index model
set.seed(1234)
n <- 100
p <- 10
x <- matrix(rnorm(n * p), n, p)
error <- rnorm(n)
y <- 3 * x[, 1] + x[, 2] + error
tau <- 0.5
out <- cqs(x, y, tau, dtau = 1)
out
# without specifying dtau
out <- cqs(x, y, tau)
out
out$qvectors[, 1:out$dtau]
set.seed(1234)
n <- 100
x <- rnorm(n)
error <- rnorm(n)
y <- x^2 + error
tau <- 0.5
llqrcv(x, y, tau = tau)
x <- rnorm(100)
y <- rnorm(100)
plot(x,y)
oldpar <- par(no.readonly = TRUE)
par(mfrow=c(2,2))
plot(x,y)
plot(x,y)
plot(x,y)
plot(x,y)
plot(x,y)
plot(x,y)
par(oldpar)
plot(x,y)
plot(x,y)
par(mfrow=c(2,3))
plot(x,y)
oldpar <- par(no.readonly = TRUE)
par(mfrow=c(2,3))
plot(x,y)
par(oldpar)
plot(x,y)
par(mfrow=c(1,1))
oldpar <- par(no.readonly = TRUE)
par(mfrow=c(2,3))
plot(x,y)
plot(x,y)
plot(x,y)
par(oldpar)
plot(x,y)
# estimate the directions of a single-index model
set.seed(1234)
n <- 100
p <- 10
x <- matrix(rnorm(n * p), n, p)
error <- rnorm(n)
y <- 3 * x[, 1] + x[, 2] + error
tau <- 0.5
out <- cqs(x, y, tau, dtau = 1)
out
# without specifying dtau
out <- cqs(x, y, tau)
out
out$qvectors[, 1:out$dtau]
# Example 1
# estimate the function at a specific quantile level for simulated data
set.seed(1234)
n <- 100
x <- rnorm(n)
error <- rnorm(n)
y <- (x + 1)^3 + 0.1 * (x - 2)^3 + error
tau <- 0.5
plot(x, y, main = tau)
points(x, llqr(x, y, tau = tau)$ll_est, col = 'red', pch = 16)
# Example 2
# estimate the function at a point x0
set.seed(1234)
n <- 100
x <- rnorm(n)
error <- rnorm(n)
y <- (x + 1)^3 + 0.1 * (x - 2)^3 + error
tau <- 0.5
x0 <- 1
llqr(x, y, tau = tau, x0 = x0)
# Example 3
# estimate the function for different quantile levels
data(mcycle, package = "MASS")
attach(mcycle)
plot(times, accel, xlab = "milliseconds", ylab = "acceleration")
taus <- c(0.1, 0.25, 0.5, 0.75, 0.9)
for(i in 1:length(taus)) {
fit <- llqr(times, accel, tau = taus[i])$ll_est
lines(times, fit, lty = i)
}
legend(45, -50, c("tau=0.1","tau=0.25","tau=0.5","tau=0.75", "tau=0.9"),
lty=1:length(taus))
# Example 4
# demonstrate a situation where the dimension of the predictor is large and
# the local linear fitting meets the 'curse of dimensionality' problem
set.seed(1234)
n <- 100
p <- 10
x <- matrix(rnorm(n * p), n, p)
error <- rnorm(n)
y <- 3 * x[, 1] + x[, 2] + error
tau <- 0.5
# use the following instead of llqr(x, y, tau = tau)
fit.alt <- llqr(x, y, tau = tau, h=1)
fit.alt
set.seed(1234)
n <- 100
x <- rnorm(n)
error <- rnorm(n)
y <- x^2 + error
tau <- 0.5
llqrcv(x, y, tau = tau)
devtools::check_win_devel()
devtools::check_rhub()
devtools::submit_cran()
devtools::build()
cran_downloads(packages="quantdr", when="last-week")
install.packages("cranlogs")
library(cranlogs)
cran_downloads(packages="quantdr", when="last-week")
cran_downloads(packages="quantdr", when="last-week")
cran_downloads(packages="quantdr", when="this-week")
cran_downloads(packages="quantdr", when="last-week")
cran_downloads(packages="quantdr", when="last-day")
library(rlang)
# separate description of the action from the action itself
z <- rlang::expr(y <- x * 10)
z
# if you want to evaluate it, use eval()
x <- 4
eval(z)
y
# Abstract syntax trees
# draw trees using lobstr::ast()
lobstr::ast(f(x, "y", 1))
# Abstract syntax trees
# draw trees using lobstr::ast()
lobstr::ast(mean(x))
lobstr::ast(f(g(1, 2), h(3, 4, i())))
ast(
f(x, y) # important!
)
lobstr::ast(y <- x)
ast(
f(x, y) # important!
)
lobstr::ast(y <- x)
lobstr::ast(
f(x, y) # important!
)
lobstr::ast(y <- x)
lobstr::ast(y <  -x)
4*(0.5)^3 - 12 * (0.5)^4 + 48*(0.5)^5/5
0.05-0.625
0.05-0.65
0.05-0.0625
#####################################################
# Last Modified: October 2, 2020
#####################################################
library(quantdr)
library(quantdr)
library(pracma)
library(dr)
library(purrr)
library(MASS)
#####################################################
# Modified-BIC type criterion for structural dimension
# selection
#####################################################
bic_d <- function(lambdas, n) {
lambdas <- sort(lambdas, decreasing = TRUE)
p <- length(lambdas)
gn <- as.null(p)
for (i in 1:length(lambdas)) {
gn[i] <- n * sum((lambdas[1:i])^2) / sum((lambdas)^2) -
2 * (n^ (3 / 4) / p) * i * (i + 1) / 2
}
which(gn == max(gn))
}
#####################################################
# Gaussian process
#####################################################
# Simulates a Gaussian process with a given kernel
#
# args:
#   from: numeric for the starting location of the sequence
#   to: numeric for the ending location of the sequence
#   K: a function that corresponds to the kernel (covariance function) of
#      the process; must give numeric outputs, and if this won't produce a
#      positive semi-definite matrix, it could fail; default is a Wiener
#      process
#   start: numeric for the starting position of the process; if NULL, could
#      be randomly generated with the rest
#   m: positive integer for the number of points in the process to simulate
#
# return:
#   A data.frame with variables "t" for the time index and "xt" for the value
#   of the process
gaussprocess <- function(from = 0, to = 1, K = function(s, t) {min(s, t)},
start = NULL, m = 1000) {
t <- seq(from = from, to = to, length.out = m)
Sigma <- sapply(t, function(s1) {
sapply(t, function(s2) {
K(s1, s2)
})
})
path <- MASS::mvrnorm(mu = rep(0, times = m), Sigma = Sigma)
if (!is.null(start)) {
path <- path - path[1] + start  # Must always start at "start"
}
return(data.frame("t" = t, "xt" = path))
}
m <- seq(5, 30, by = 5)
m
nsimu <- 100
m <- seq(5, 30, by = 5)
n <- 200
p <- 10
tau <- c(0.1, 0.25, 0.5, 0.75, 0.9)
beta <- c(3, 1.5, 0, 0, 2, rep(0, p - 5))
dtau <- 1
K <- function(s, t) exp(-0.5 * abs(s - t))
est_error <- array(0, c(nsimu, length(tau), length(m)))
M=1
j=1
k=1
set.seed(1234)
x <- matrix(0, n * m[M], p)
error <- rep(0, n * m[M])
t_time <- c(1:m[M])
alpha <- sin(2 * pi * t_time / 30)
for (s in 1:n) {
for (t in 1:p) {
x[((s - 1) * m[M] + 1):(s * m[M]), t] <- gaussprocess(1, m[M], K, m = m[M])$xt
}
}
for (s in 1:n) {
error[((s - 1) * m[M] + 1):(s * m[M])] <- gaussprocess(1, m[M], K, m = m[M])$xt
}
y <- alpha + x %*% beta + error
yt <- list()
xt <- list()
for (l in 1:m[M]) {
if (l != m[M]) {
index <- (1:(n * m[M]) %% m[M]) == l
} else {
index <- (1:(n * m[M]) %% m[M]) == 0
}
yt[[l]] <- y[index]
xt[[l]] <- x[index, ]
}
for (k in 1:length(tau)) {
beta_hat_CPQS <- as.null()
for (l in 1:m[M]) {
beta_hat_CPQS <- cbind(beta_hat_CPQS, cqs(xt[[l]], yt[[l]], tau = tau[k], dtau = dtau)$qvectors[, 1:dtau])
}
b_CPQS <- beta_hat_CPQS
B_CPQS <- tcrossprod(b_CPQS, b_CPQS)
out_CPQS <- eigen(B_CPQS)
beta_final_CPQS <- out_CPQS$vectors[, 1:dtau]
beta_final_CPQS <- 3 * beta_final_CPQS / beta_final_CPQS[1]
# estimation error
est_error[j, k, M] <- (pracma::subspace(beta, beta_final)) / (pi / 2)
}
for (k in 1:length(tau)) {
beta_hat_CPQS <- as.null()
for (l in 1:m[M]) {
beta_hat_CPQS <- cbind(beta_hat_CPQS, cqs(xt[[l]], yt[[l]], tau = tau[k], dtau = dtau)$qvectors[, 1:dtau])
}
b_CPQS <- beta_hat_CPQS
B_CPQS <- tcrossprod(b_CPQS, b_CPQS)
out_CPQS <- eigen(B_CPQS)
beta_final_CPQS <- out_CPQS$vectors[, 1:dtau]
beta_final_CPQS <- 3 * beta_final_CPQS / beta_final_CPQS[1]
# estimation error
est_error[j, k, M] <- (pracma::subspace(beta, beta_final_CPQS)) / (pi / 2)
}
est_error[j, , M]
beta
beta_final_CPQS
apply(est_error, c(2,3), mean)
m
plot(m, means_errors[3, ])
means_errors <- apply(est_error, c(2, 3), mean)
sds_errors <- apply(est_error, c(2, 3), sd)
plot(m, means_errors[3, ])
means_errors <- apply(est_error, c(2, 3), mean)
sds_errors <- apply(est_error, c(2, 3), sd)
plot(m, means_errors[3, ], type = 'l')
nsimu <- 100
m <- seq(5, 30, by = 5)
n <- 200
p <- 10
tau <- c(0.1, 0.25, 0.5, 0.75, 0.9)
beta <- c(3, 1.5, 0, 0, 2, rep(0, p - 5))
dtau <- 1
K <- function(s, t) exp(-0.5 * abs(s - t))
est_error <- array(0, c(nsimu, length(tau), length(m)))
for (M in 1:length(m)) {
set.seed(1234)
for (j in 1:nsimu){
x <- matrix(0, n * m[M], p)
error <- rep(0, n * m[M])
t_time <- c(1:m[M])
alpha <- sin(2 * pi * t_time / 30)
for (s in 1:n) {
for (t in 1:p) {
x[((s - 1) * m[M] + 1):(s * m[M]), t] <- gaussprocess(1, m[M], K, m = m[M])$xt
}
}
for (s in 1:n) {
error[((s - 1) * m[M] + 1):(s * m[M])] <- gaussprocess(1, m[M], K, m = m[M])$xt
}
y <- alpha + x %*% beta + error
yt <- list()
xt <- list()
for (l in 1:m[M]) {
if (l != m[M]) {
index <- (1:(n * m[M]) %% m[M]) == l
} else {
index <- (1:(n * m[M]) %% m[M]) == 0
}
yt[[l]] <- y[index]
xt[[l]] <- x[index, ]
}
for (k in 1:length(tau)) {
beta_hat_CPQS <- as.null()
for (l in 1:m[M]) {
beta_hat_CPQS <- cbind(beta_hat_CPQS, cqs(xt[[l]], yt[[l]], tau = tau[k], dtau = dtau)$qvectors[, 1:dtau])
}
b_CPQS <- beta_hat_CPQS
B_CPQS <- tcrossprod(b_CPQS, b_CPQS)
out_CPQS <- eigen(B_CPQS)
beta_final_CPQS <- out_CPQS$vectors[, 1:dtau]
beta_final_CPQS <- 3 * beta_final_CPQS / beta_final_CPQS[1]
# estimation error
est_error[j, k, M] <- (pracma::subspace(beta, beta_final_CPQS)) / (pi / 2)
}
}
}
means_errors <- apply(est_error, c(2, 3), mean)
sds_errors <- apply(est_error, c(2, 3), sd)
plot(m, means_errors[3, ], type = 'l')
par(mfrow=c(2, 3))
for (i in 1:length(taus)) {
plot(m, means_errors[i, ], type = 'l')
}
for (i in 1:length(tau)) {
plot(m, means_errors[i, ], type = 'l')
}
means_errors <- apply(est_error, c(2, 3), mean)
sds_errors <- apply(est_error, c(2, 3), sd)
par(mfrow=c(2, 3))
for (i in 1:length(tau)) {
plot(m, means_errors[i, ], type = 'l', ylab = 'mean estimation error')
}
par(mfrow=c(2, 3))
for (i in 1:length(tau)) {
plot(m, means_errors[i, ], type = 'l', ylab = 'mean estimation error', main = tau[i])
}
for (i in 1:length(tau)) {
plot(m, means_errors[i, ], type = 'l', ylab = 'mean estimation error', main = expression(paste(tau, tau[i])))
}
par(mfrow=c(2, 3))
for (i in 1:length(tau)) {
plot(m, means_errors[i, ], type = 'l', ylab = 'mean estimation error', main = expression(paste(tau), tau[i]))
}
par(mfrow=c(2, 3))
for (i in 1:length(tau)) {
plot(m, means_errors[i, ], type = 'l', ylab = 'mean estimation error', main = tau[i])
}
means_errors
sds_errors
setwd("~/Desktop")
pdf(paste('Ex4_ModelI.pdf'), width = 9, height = 7.5)
par(mfrow=c(2, 3))
for (i in 1:length(tau)) {
plot(m, means_errors[i, ], type = 'l', ylab = 'mean estimation error', main = tau[i])
}
dev.off()
pdf(paste('Ex4_ModelI.pdf'), width = 9, height = 6)
par(mfrow=c(2, 3))
for (i in 1:length(tau)) {
plot(m, means_errors[i, ], type = 'l', ylab = 'mean estimation error', main = tau[i])
}
dev.off()
pdf(paste('Ex4_ModelI.pdf'), width = 9, height = 6.5)
par(mfrow=c(2, 3))
for (i in 1:length(tau)) {
plot(m, means_errors[i, ], type = 'l', ylab = 'mean estimation error', main = tau[i])
}
dev.off()
layout(matrix(c(1, 0, 1, 2, 3, 2, 3, 4, 5, 4, 5, 0), 2, 6))
for (i in 1:length(tau)) {
plot(m, means_errors[i, ], type = 'l', ylab = 'mean estimation error', main = tau[i])
}
pdf(paste('Ex4_ModelI.pdf'), width = 9, height = 6.5)
layout(matrix(c(1, 0, 1, 2, 3, 2, 3, 4, 5, 4, 5, 0), 2, 6))
for (i in 1:length(tau)) {
plot(m, means_errors[i, ], type = 'l', ylab = 'mean estimation error', main = tau[i])
}
dev.off()
pdf(paste('Ex4_ModelI_long.pdf'), width = 9, height = 6.5)
layout(matrix(c(1, 0, 1, 2, 3, 2, 3, 4, 5, 4, 5, 0), 2, 6))
for (i in 1:length(tau)) {
plot(m, means_errors[i, ], type = 'l', ylab = 'mean estimation error', main = tau[i])
}
dev.off()
layout(matrix(c(1, 0, 1, 4, 2, 4, 2, 5, 3, 5, 3, 0), 2, 6))
for (i in 1:length(tau)) {
plot(m, means_errors[i, ], type = 'l', ylab = 'mean estimation error', main = tau[i])
}
pdf(paste('Ex4_ModelI_long.pdf'), width = 9, height = 6.5)
layout(matrix(c(1, 0, 1, 4, 2, 4, 2, 5, 3, 5, 3, 0), 2, 6))
for (i in 1:length(tau)) {
plot(m, means_errors[i, ], type = 'l', ylab = 'mean estimation error', main = tau[i])
}
dev.off()
library(cranlogs)
cran_downloads(packages="quantdr", when="last-week")
cran_downloads(packages="quantdr", when="last-week")
cran_downloads(packages="quantdr", when="last-day")
cran_downloads(packages="quantdr", when="last-week")
cran_downloads(packages="quantdr", when="last-week")
cran_downloads(packages="quantdr", when="last-week")
6+11+25
(70-65)/sqrt(15/35)
(67-65)/sqrt(15/35)
(60-65)/sqrt(15/35)
(66-65)/sqrt(15/35)
1-0.9370
-1.645*sqrt(15/35) + 65
3/sqrt(27/35)
2/sqrt(27/35)
1-0.9887
library(quantdr)
devtools::document()
devtools::load_all(".")
