# true direction that spans each central quantile subspace
beta_true <- c(3, 1, rep(0, p - 2))
beta_true / sqrt(sum(beta_true^2))
# sufficient direction
dir1 <- x %*% beta_true
# Estimate the directions of each central quantile subspace
# Since dtau is known to be one, the algorithm will produce only one vector
out <- matrix(0, p, length(taus))
for (i in 1:length(taus)) {
out[, i] <- cqs(x, y, tau = taus[i], dtau = 1)$qvectors
}
out
# compare each estimated direction with the true one using the angle between the two subspaces
library(pracma)
for (i in 1:length(taus)) {
print(subspace(out[, i], beta_true) / (pi / 2)) # the angle is measured in radians, so divide by pi/2
}
# Estimate and plot the conditional quantile function using the new sufficient predictors
library(ggplot2)
newx <- x %*% out
qhat <- as.null()
for (i in 1:length(taus)) {
qhat <- c(qhat, llqr(newx[, i], y, tau = taus[i])$ll_est)
}
data1 <- data.frame(rep(dir1, n), rep(y, n), c(newx), rep(taus, each = n), qhat)
names(data1) <- c("dir1", "y", "newx", "quantiles", 'qhat')
ggplot(data1, aes(x = dir1, y = y)) + geom_point(size = 3) +
geom_point(aes(x = dir1, qhat), colour = 'red') +
facet_wrap(~quantiles, ncol = 3) + xlab('sufficient direction')
library(quantdr)
## basic example code - a homoscedastic single-index model
# Setting
set.seed(1234)
n <- 100
p <- 10
taus <- c(0.1, 0.25, 0.5, 0.75, 0.9)
x <- matrix(rnorm(n * p), n, p)
error <- rnorm(n)
y <- 3 * x[, 1] + x[, 2] + error
# true direction that spans each central quantile subspace
beta_true <- c(3, 1, rep(0, p - 2))
beta_true / sqrt(sum(beta_true^2))
# sufficient direction
dir1 <- x %*% beta_true
# Estimate the directions of each central quantile subspace
# Since dtau is known to be one, the algorithm will produce only one vector
out <- matrix(0, p, length(taus))
for (i in 1:length(taus)) {
out[, i] <- cqs(x, y, tau = taus[i], dtau = 1)$qvectors
}
out
# compare each estimated direction with the true one using the angle between the two subspaces
library(pracma)
for (i in 1:length(taus)) {
print(subspace(out[, i], beta_true) / (pi / 2)) # the angle is measured in radians, so divide by pi/2
}
# Estimate and plot the conditional quantile function using the new sufficient predictors
library(ggplot2)
newx <- x %*% out
qhat <- as.null()
for (i in 1:length(taus)) {
qhat <- c(qhat, llqr(newx[, i], y, tau = taus[i])$ll_est)
}
data1 <- data.frame(rep(dir1, n), rep(y, n), c(newx), rep(taus, each = n), qhat)
names(data1) <- c("dir1", "y", "newx", "quantiles", 'qhat')
ggplot(data1, aes(x = dir1, y = y)) + geom_point() +
geom_point(aes(x = dir1, qhat), colour = 'red') +
facet_wrap(~quantiles, ncol = 3) + xlab('sufficient direction')
devtools::document()
devtools::load_all(".")
devtools::release()
spell_check()
library(devtools)
spell_check()
devtools::release()
check_rhub()
devtools::release()
check_win_devel()
devtools::release()
devtools::document()
devtools::load_all(".")
devtools::release()
check_rhub()
library(devtools)
check_rhub()
devtools::release()
check_win_devel()
devtools::release()
devtools::load_all(".")
devtools::load_all(".")
devtools::load_all(".")
# Example 1
# estimate the function at a specific quantile level for simulated data
set.seed(1234)
n <- 100
x <- rnorm(n)
error <- rnorm(n)
y <- (x + 1)^3 + 0.1 * (x - 2)^3 + error
tau <- 0.5
plot(x, y, main = tau)
points(x, llqr(x, y, tau = tau)$ll_est, col = 'red', pch = 16)
llqr(x, y, tau = tau)
devtools::load_all(".")
# Example 1
# estimate the function at a specific quantile level for simulated data
set.seed(1234)
n <- 100
x <- rnorm(n)
error <- rnorm(n)
y <- (x + 1)^3 + 0.1 * (x - 2)^3 + error
tau <- 0.5
plot(x, y, main = tau)
points(x, llqr(x, y, tau = tau)$ll_est, col = 'red', pch = 16)
llqr(x, y, tau = tau)
# Example 2
# estimate the function at a point x0
set.seed(1234)
n <- 100
x <- rnorm(n)
error <- rnorm(n)
y <- (x + 1)^3 + 0.1 * (x - 2)^3 + error
tau <- 0.5
x0 <- 1
llqr(x, y, tau = tau, x0 = x0)
# Example 3
# estimate the function for different quantile levels
data(mcycle, package = "MASS")
attach(mcycle)
plot(times, accel, xlab = "milliseconds", ylab = "acceleration")
taus <- c(0.1, 0.25, 0.5, 0.75, 0.9)
for(i in 1:length(taus)) {
fit <- llqr(times, accel, tau = taus[i])$ll_est
lines(times, fit, lty = i)
}
legend(45, -50, c("tau=0.1","tau=0.25","tau=0.5","tau=0.75", "tau=0.9"),
lty=1:length(taus))
llqr(times, accel, tau = taus[i])
# estimate the directions of a single-index model
set.seed(1234)
n <- 100
p <- 10
x <- matrix(rnorm(n * p), n, p)
error <- rnorm(n)
y <- 3 * x[, 1] + x[, 2] + error
tau <- 0.5
out <- cqs(x, y, tau, dtau = 1)
out
# without specifying dtau
out <- cqs(x, y, tau)
out
out$qvectors[, 1:out$dtau]
n <- 100
p <- 10
x <- matrix(rnorm(n * p), n, p)
error <- rnorm(n)
y <- 3 * x[, 1] + x[, 2] + error
tau <- 0.5
out <- cqs(x, y, tau, dtau = 1)
out
# without specifying dtau
out <- cqs(x, y, tau)
out
out$qvectors[, 1:out$dtau]
set.seed(1234)
n <- 100
p <- 10
x <- matrix(rnorm(n * p), n, p)
error <- rnorm(n)
y <- 3 * x[, 1] + x[, 2] + error
tau <- 0.5
out <- cqs(x, y, tau, dtau = 1)
out
# without specifying dtau
out <- cqs(x, y, tau)
out
out$qvectors[, 1:out$dtau]
sd(y)
?VaR
library(PerformanceAnalytics)
?VaR
data(edhec)
VaR(edhec, p=.95, method="historical")
View(edhec)
?edhec
plot.ts(edhec$`Convertible Arbitrage`)
plot.ts(edhec$`CTA Global`)
plot.ts(edhec$`Distressed Securities`)
VaR(edhec, p=.95, method="historical")
?edhec
library(quantdr)
devtools::load_all(".")
devtools::load_all(".")
devtools::load_all(".")
square(2)
sqrt(2)
devtools::check_win_devel()
devtools::check_rhub()
devtools::load_all(".")
devtools::check_rhub()
?ValAR
y <- edhec[1, ]
n <- length(y)
n
library(quantdr)
y <- edhec[, 1]
n <- length(y)
p <- 5
n
y
library(quantreg)
library(quantdr)
devtools::load_all(".")
# Example 1
# estimate the Value-at-Risk for the next day without a moving window
data(edhec, package = "PerformanceAnalytics")
y <- as.vector(edhec[, 1]) # Convertible Arbitrage
length(y)
p <- 5 # use the last 5 as predictor variables
tau <- 0.05
ValAR(y, p, tau)
newy <- as.vector(edhec[1:(n - m + 1), 1])
m <- 50
newy <- as.vector(edhec[1:(n - m + 1), 1])
length(newy)
length(edhec[(n - m + 2) : n, 1])
newy <- as.vector(edhec[1:(n - m ), 1])
length(newy)
length(226:275)
m <- 50 # predict the 5% VaR of the last 50 observations.
newy <- as.vector(edhec[1:(n - m ), 1]) # the available vector of returns
VaRest <- as.null(m)
for (i in 1:m){
VaRest[i] <- ValAR(r[1:(n - m + i - 1)], p, tau)
}
m <- 50 # predict the 5% VaR of the last 50 observations.
newy <- as.vector(edhec[1:(n - m ), 1]) # the available vector of returns
VaRest <- as.null(m)
for (i in 1:m){
VaRest[i] <- ValAR(newy[1:(n - m + i - 1)], p, tau)
}
m <- 50 # predict the 5% VaR of the last 50 observations.
newy <- as.vector(edhec[1:(n - m ), 1]) # the available vector of returns
newy
i
m <- 50 # predict the 5% VaR of the last 50 observations.
y <- as.vector(edhec[, 1]) # the available vector of returns
VaRest <- as.null(m)
for (i in 1:m){
VaRest[i] <- ValAR(y[1:(n - m + i - 1)], p, tau)
}
i
VaRest
devtools::load_all(".")
devtools::load_all(".")
devtools::load_all(".")
data(edhec, package = "PerformanceAnalytics")
View(edhec)
y <- as.vector(edhec[, 1]) # Convertible Arbitrage
View(y)
?edhec
data(edhec, package = "PerformanceAnalytics")
library(PerformanceAnalytics)
?edhec
View(edhec)
# Example 2
# estimate the Value-at-Risk for the next day with a moving window
data(edhec, package = "PerformanceAnalytics")
y <- as.vector(edhec[, 2]) # CTA Global
p <- 5 # use the last 5 as predictor variables
tau <- 0.05
movwind = 250
ValAR(y, p, tau, movwind)
# compare it with the historical Value-at-Risk calculation
PerformanceAnalytics::VaR(y, 0.95, method = 'historical')
# Example 1
# estimate the Value-at-Risk for the next day without a moving window
data(edhec, package = "PerformanceAnalytics")
y <- as.vector(edhec[, 1]) # Convertible Arbitrage
length(y)
p <- 5 # use the last 5 as predictor variables
tau <- 0.05
ValAR(y, p, tau)
# compare it with the historical Value-at-Risk calculation
PerformanceAnalytics::VaR(y, 0.95, method = 'historical')
# Example 1
# estimate the Value-at-Risk for the next day without a moving window
data(edhec, package = "PerformanceAnalytics")
y <- as.vector(edhec[, 1]) # Convertible Arbitrage
length(y)
p <- 5 # use the last 5 as predictor variables
tau <- 0.05
ValAR(y, p, tau)
# compare it with the historical Value-at-Risk calculation
PerformanceAnalytics::VaR(y, 0.95, method = 'historical')
# Example 1
# estimate the Value-at-Risk for the next day without a moving window
data(edhec, package = "PerformanceAnalytics")
y <- as.vector(edhec[, 1]) # Convertible Arbitrage
length(y)
p <- 5 # use the last 5 as predictor variables
tau <- 0.05
ValAR(y, p, tau)
# compare it with the historical Value-at-Risk calculation
PerformanceAnalytics::VaR(y, 0.95, method = 'historical')
# Example 2
# estimate the Value-at-Risk for the next day with a moving window
data(edhec, package = "PerformanceAnalytics")
y <- as.vector(edhec[, 2]) # CTA Global
p <- 5 # use the last 5 as predictor variables
tau <- 0.05
movwind = 250
ValAR(y, p, tau, movwind)
# compare it with the historical Value-at-Risk calculation
PerformanceAnalytics::VaR(y, 0.95, method = 'historical')
devtools::check_rhub()
devtools::load_all(".")
devtools::check_rhub()
devtools::load_all(".")
devtools::load_all(".")
devtools::check_rhub()
devtools::load_all(".")
library(quantdr)
devtools::load_all(".")
library(quantdr)
devtools::check_rhub()
devtools::check_rhub()
library(PerformanceAnalytics)
data(edhec, package = "PerformanceAnalytics")
head(edhec)
View(edhec)
library(quantdr)
y <- y[1:(n - size)]
size <- 50
y <- y[1:(n - size)]
length(y)
n
library(PerformanceAnalytics)
data(edhec, package = "PerformanceAnalytics")
head(edhec)
y <- as.vector(edhec[, 1])
n <- length(y)
p <- 5
tau <- 0.05
ValAR(y, p = p, tau = tau)
devtools::load_all(".")
devtools::load_all(".")
devtools::load_all(".")
library(quantdr)
library(quantdr)
library(PerformanceAnalytics)
data(edhec, package = "PerformanceAnalytics")
head(edhec)
y <- as.vector(edhec[, 1])
n <- length(y)
p <- 5
tau <- 0.05
ValAR(y, p = p, tau = tau)
VaR(y, 0.95, method = 'historical')
size <- 50
y <- y[1:(n - size)]
length(y)
n
265-50
y <- as.vector(edhec[, 1])
n <- length(y)
p <- 5
tau <- 0.05
ValAR(y, p = p, tau = tau)
size <- 50
VaRest <- as.null(size)
for (i in 1:size){
VaRest[i] <- ValAR(r[1:(n - size + i - 1)], p, tau)
}
size <- 50
VaRest <- as.null(size)
for (i in 1:size){
VaRest[i] <- ValAR(y[1:(n - size + i - 1)], p, tau)
}
i
devtools::load_all(".")
library(quantdr)
library(PerformanceAnalytics)
data(edhec, package = "PerformanceAnalytics")
head(edhec)
y <- as.vector(edhec[, 2])
n <- length(y)
p <- 5
tau <- 0.05
ValAR(y, p = p, tau = tau)
VaR(y, 0.95, method = 'historical')
size <- 50
VaRest <- as.null(size)
for (i in 1:size){
VaRest[i] <- ValAR(y[1:(n - size + i - 1)], p, tau)
}
plot.ts(y[(n - size + 1):n], ylim = range(y[(n - size + 1):n], VaRest))
plot.ts(y[(n - size + 1):n], ylim = range(y[(n - size + 1):n], VaRest), ylab = 'returns')
lines(VaRest, col = 'red')
plot.ts(y[(n - size + 1):n], ylim = range(y[(n - size + 1):n], VaRest), ylab = 'returns')
lines(VaRest, col = 'red')
VaRest
length(y[(n - size + 1):n])
plot.ts(y[(n - size + 1):n], ylim = range(y[(n - size + 1):n], VaRest), ylab = 'returns')
lines(VaRest, col = 'red')
sum(y[(n - size + 1):n] < VaRest)
sum(y[(n - size + 1):n] < VaRest) / size * 100
sum(y[(n - size + 1):n] < VaRest) / size
size <- 100
VaRest <- as.null(size)
for (i in 1:size){
VaRest[i] <- ValAR(y[1:(n - size + i - 1)], p, tau)
}
plot.ts(y[(n - size + 1):n], ylim = range(y[(n - size + 1):n], VaRest), ylab = 'returns')
lines(VaRest, col = 'red')
sum(y[(n - size + 1):n] < VaRest) / size
taus <- c(0.01, 0.025, 0.05)
VaRest <- as.matrix(size, length(taus))
for (i in 1:size) {
for (j in 1:length(taus)) {
VaRest[i, j] <- ValAR(y[1:(n - size + i - 1)], p, taus[j])
}
}
taus <- c(0.01, 0.025, 0.05)
VaRest <- as.matrix(0, size, length(taus))
for (i in 1:size) {
for (j in 1:length(taus)) {
VaRest[i, j] <- ValAR(y[1:(n - size + i - 1)], p, taus[j])
}
}
VaRest <- as.matrix(0, size, length(taus))
ValAR(y[1:(n - size + i - 1)], p, taus[j])
VaRest[i, j]
i
j
VaRest <- as.matrix(0, size, length(taus))
taus <- c(0.01, 0.025, 0.05)
VaRest <- matrix(0, size, length(taus))
for (i in 1:size) {
for (j in 1:length(taus)) {
VaRest[i, j] <- ValAR(y[1:(n - size + i - 1)], p, taus[j])
}
}
plot.ts(y[(n - size + 1):n], ylim = range(y[(n - size + 1):n], VaRest), ylab = 'returns')
lines(VaRest[, 1], col = 'red')
lines(VaRest[, 2], col = 'blue')
lines(VaRest[, 3], col = 'green')
sum(y[(n - size + 1):n] < VaRest[, 1]) / size
sum(y[(n - size + 1):n] < VaRest[, 2]) / size
sum(y[(n - size + 1):n] < VaRest[, 3]) / size
devtools::load_all(".")
devtools::load_all(".")
devtools::load_all(".")
library(quantdr)
set.seed(1234)
n <- 100
p <- 10
tau <- 0.5
x <- matrix(rnorm(n * p), n, p)
error <- rnorm(n)
y <- 3 * x[, 1] + x[, 2] + error
out1 <- cqs(x, y, tau = tau, dtau = 1)
out2 <- cqs(x, y, tau = tau)
library(pracma)
beta_true <- c(3, 1, rep(0, p - 2))
beta_hat1 <- out1$qvectors
beta_hat2 <- out2$qvectors[, 1:out2$dtau]
newx <- x %*% beta_hat1
qhat1 <- llqr(newx, y, tau)
qhat2 <- llqr(newx, y, tau, method = "CV")
qhat3 <- llqr(newx, y, tau, h = 1)
plot(true_dir, y, xlab = 'sufficient direction')
true_dir <- x %*% beta_true
plot(true_dir, y, xlab = 'sufficient direction')
points(true_dir, qhat1$ll_est, col = 'red')
plot(true_dir, y, xlab = 'sufficient direction', pch = 16)
points(true_dir, qhat1$ll_est, col = 'red', pch = 16)
true_dir <- x %*% beta_true
plot(true_dir, y, xlab = 'sufficient direction', pch = 16)
points(true_dir, qhat1$ll_est, col = 'red', pch = 16)
true_dir <- x %*% beta_true
data1 <- data.frame(true_dir, y, qhat1$ll_est)
ggplot(data1, aes(x = true_dir, y=y)) + geom_point(size = 1) +
geom_point(aes(x = true_dir, qhat1$ll_est), colour = 'red', size = 1) +
xlab('sufficient direction')
library(ggplot2)
true_dir <- x %*% beta_true
data1 <- data.frame(true_dir, y, qhat1$ll_est)
ggplot(data1, aes(x = true_dir, y=y)) + geom_point(size = 1) +
geom_point(aes(x = true_dir, qhat1$ll_est), colour = 'red', size = 1) +
xlab('sufficient direction')
devtools::check_rhub()
taus <- c(0.1, 0.25, 0.5, 0.75, 0.9)
out3 <- matrix(0, p, length(taus))
for (i in 1:length(taus)) {
out3[, i] <- cqs(x, y, tau = taus[i], dtau = 1)$qvectors
}
out3
newx <- x %*% out3
oldpar <- par(no.readonly = TRUE)
par(mfrow=c(2,3))
qhat_tau <- as.null()
for (i in 1:length(taus)) {
plot(true_dir, y, xlab = "sufficient direction", ylab = "y", main = taus[i], pch = 16)
qhat_tau <- llqr(newx[, i], y, tau = taus[i])$ll_est
points(true_dir, qhat_tau, pch = 16, col = "red")
}
par(oldpar)
true_dir <- x %*% beta_true
plot(true_dir, y, xlab = "sufficient direction", ylab = "y", pch = 16)
points(true_dir, qhat1$ll_est, pch = 16, col = 'red')
library(quantdr)
devtools::check_rhub()
